---
title: "5-SOD"
output: html_document
date: "2024-07-10"
---

```{r, eval =TRUE, message=FALSE}
library(knitr)
library(tidyverse)
library(tidyr)
library(dplyr)
library(hrbrthemes)
library(ggplot2)
library(car)
library(RColorBrewer)
library(ggpubr)
knitr::opts_chunk$set(echo = TRUE,
                      eval = TRUE)
```

# Background
An LC50 determination for nickel on *Botryllus schlosseri* was completed in Spring Quarter 2024. Specimens were snap frozen at the 24 and 96 hour mark to assess for accumulation of Superoxide Dismutase 1 (SOD1). SOD1 is an endogenous antioxidant with a primary function involving the removal of reactive oxygen species (ROS). 

Nickel genotoxicity functions indirectly through the resultant intracellular accumulation of ROS in most animal cells. ROS cause double and single stranded breaks to the DNA which inevitably may result in mutations forming at the cellular attempts to repair the DNA.

Here we explore the effects of increasing concentrations of nickel on the accumulation of SOD1 in *B. schlosseri*.


# Retrieving Data from Google Sheets

## SOD Data

Make sure you have made your Google sheet publicly available to anyone that has the link. If you make any updates to the sheet just re-curl the data, meaning just re-run the code below.

I apologize for not making a relative path. Just modify what is after "tee" to your own directory path.

```{r, engine='bash', eval=FALSE}
cd ..

curl -L https://docs.google.com/spreadsheets/d/1vNxX2tBdEa0Ibyd4mFdru5sAZx0aipv37-y-hkqvJq4/export?exportFormat=csv | tee data/SOD.csv
```
## BCA Data No Raw Absorbance

```{r, engine='bash', eval = FALSE}
cd ..

curl -L https://docs.google.com/spreadsheets/d/1mKhd95gn_tith8fJbYjX3jGyrO-Y4mWKCoCKdTVZFHY/export?exportFormat=csv | tee data/BCA_noRawAbs.csv
```

## BCA Data Raw Absorbance

```{r, engine='bash', eval = FALSE}
cd ..

curl -L https://docs.google.com/spreadsheets/d/180-3tk6UJCAyGFkj0JzIqdBfeG5nf0S4BTjKkK0sou8/export?exportFormat=csv | tee data/BCA_RawAbs.csv
```

## Metadata

Mostly it has the homogenization number and tunicate ID. We are gonna merge this with the other data frames.

```{r, engine='bash'}
cd ..
curl -L https://docs.google.com/spreadsheets/d/1eDGpgtTB_yBolNCtSxVU2U_oajdm3Oi7guIREc7asRc/export?exportFormat=csv | tee data/metadata.csv
```

## Blastogenic Data
```{r, engine='bash'}
cd ..
curl -L https://docs.google.com/spreadsheets/d/1JtJO3EX06BYK4pYwZZ7b7ZCoTyZcAeuTRka_9kA-yPk/export?exportFormat=csv | tee data/morph.csv
```


## QAQC data

Will need to exclude as they were not processed in assay:
- DM042024_C02 (1 mg/L condition) declined in health.
- DM022024_C05 (control) needs to be redone we have it for the BCA but not the SOD. Ran out of Xan. Ox.  

Results in 8 replicates for 100 mg/L conc. and  7  for the 1 mg/L conc. + control.

Look at the summaries of each data frame and make sure all the data looks right.

Theoretically, we did 8 replicates per treatment and 2 time points. 

Below we want to look at 0, 1, 100 mg/L treatments.

There should be 48 total homogenates we are looking at. Note that the SOD assay has technical duplicates and the BCA assay had technical triplicates of each of those homogenates.

Per treatment there should be:

- 32 "observations" (entries/rows) for the SOD assay 

- 48 "observations" for the BCA assay

# SOD

```{r}
setwd('..')
sod <- read.csv(file = "data/SOD.csv")
```
```{r}
sod_std_key <- tibble::tribble(
  ~standard, ~known_sod_u_ml,
  2, 2,
  3, 1,
  4, 0.5,
  5, 0.25,
  6, 0.125,
  7, 0.0625,
  8, 0
)

sod <- sod %>%
  left_join(
    sod_std_key,
    by = c("homogenate" = "standard")
  ) %>%
  mutate(
    known_sod_u_ml = if_else(type == "standard", known_sod_u_ml, NA_real_)
  )
```

## Calculate SOD from raw absorbance
```{r}
# take the adjusted raw values from pre and post incubation with the xan ox solubalization agent
sod <- sod %>%
  mutate(
    delta_abs = post_xan_ox_abs450 - pre_xan_ox_abs450
  )
```



```{r}
# take the average of each tech rep of the blank (std 8 = 0 u/mL) standard per plate
blank_df <- sod %>%
  filter(type == "standard",
         known_sod_u_ml == 0) %>%
  group_by(plate) %>%
  summarise(blank_delta = mean(delta_abs, na.rm = TRUE), .groups = 'drop')

# put the average blank for each plate in the main sod data frame
sod <- sod %>%
  left_join(blank_df, by="plate")


# here we take the average blank and then do average blank - tech rep of blank <- which is not zero 
# apparently this method of average blank - tech rep of blank is more statistically robust
sod <- sod %>%
  mutate(blank_corrected_abs = delta_abs - blank_delta)


sod %>%
  filter(type == "standard", known_sod_u_ml == 0) %>%
  group_by(plate) %>%
  summarise(
    mean_blank_corrected = mean(blank_corrected_abs, na.rm = TRUE),
    sd_blank_corrected = sd(blank_corrected_abs, na.rm = TRUE),
    .groups = "drop"
  )
# the mean_blank_corrected should be 0 or close to 0
```
## SOD standard curve
```{r}
# create a data frame for only the sod standards
std_df <- sod %>%
  filter(type == "standard",
         !is.na(known_sod_u_ml))

std_df %>%
  select(well_content, known_sod_u_ml, blank_corrected_abs) %>%
  head()


# now plot the blank-corrected standards 
ggplot(std_df, aes(x = known_sod_u_ml, y = blank_corrected_abs)) +
  geom_point(size = 3) +
  theme_classic(base_size = 14) +
  labs(
    x = "Known SOD (U/mL)",
    y = "Blank-corrected ΔA450"
  )

```


## line of best fit for std
```{r}

ggplot(std_df, aes(x = known_sod_u_ml, y = blank_corrected_abs)) +
  geom_point(size = 3) +
  stat_smooth(
    data = std_df %>% filter(known_sod_u_ml > 0),
    method = "lm",
    formula = y ~ log(x),
    se = FALSE,
    linewidth = 1
  ) +
  theme_classic(base_size = 14) +
  labs(
    x = "Known SOD (U/mL)",
    y = "Blank-corrected ΔA450"
  )

sod_fit <- lm(
  blank_corrected_abs ~ log(known_sod_u_ml),
  data = std_df %>% filter(known_sod_u_ml > 0)
)

a_coef_sod <- coef(sod_fit)[1]
b_coef_sod <- coef(sod_fit)[2]

```

## SOD Calculation in R
```{r}
# calculate sod for all wells
sod <- sod %>%
  mutate(
    sod_u_ml_calc = exp((blank_corrected_abs - a_coef_sod)/b_coef_sod)
  )


# calculate based off dilution correction (1:3)
sod <- sod %>%
  mutate(
    dilution_numeric = if_else(
      dilution_factor_unknownsample_pbs == "1:3", 3, 1
    ),
    sod_u_ml_final = sod_u_ml_calc * dilution_numeric
  )

sod %>%
  filter(type == "standard") %>%
  select(well_content, known_sod_u_ml, sod_u_ml_calc) %>%
  arrange(known_sod_u_ml)

```

Check that the model fit our data correctly 
```{r}
summary(sod_fit)
# high R^2 at 0.952 so strong fit

sod_summary <- sod %>%
  filter(type == "unknown") %>%
  group_by(plate, homogenate) %>%
  summarise(
    mean_sod = mean(sod_u_ml_final, na.rm = TRUE),
    sd_sod = sd(sod_u_ml_final, na.rm = TRUE),
    n = n(),
    .groups = "drop"
  )

```

```{r}
setwd( '..' )
write.csv(sod, "data/sod_all_wells_with_calculatedR_activity.csv", row.names = FALSE)
write.csv(sod_summary, "data/sod_homogenate_meansR.csv", row.names = FALSE)
```



# BCA
```{r}
setwd('..')
bca_raw <- read.csv(file = "data/BCA_RawAbs.csv")
bca_noRaw <-read.csv(file = "data/BCA_noRawAbs.csv")

bca <- full_join(bca_noRaw, bca_raw, by = c("well_content", "plate", "type", "assay_date", "assay"))

# extract the standard name and place in the homogenate column
bca <- bca %>%
  mutate(
    homogenate = as.character(homogenate),
    homogenate = if_else(
      type == "standard",
      str_extract(well_content, "^[A-Za-z]"),
      homogenate
    )
  )
```

## BCA standard curve
```{r}
# create a standard key
bca_std_key <- tibble::tribble(
  ~standard, ~known_mg_ml,
  "A", 0,
  "B", 0.1,
  "C", 0.2,
  "D", 0.4,
  "E", 0.8,
  "F", 1.2,
  "G", 1.6,
  "H", 2
)

bca <- bca %>%
  left_join(bca_std_key, by = c("homogenate" = "standard")) %>%
  mutate(known_mg_ml = if_else(type == "standard", known_mg_ml, NA_real_))



```


calculate the average blank absorbance value for each plate
```{r}
bca_blank_df <- bca %>%
  filter(type == "standard", known_mg_ml == 0) %>%   # 'A' standard
  group_by(plate) %>%
  summarise(bca_blank_abs = mean(abs562, na.rm = TRUE), .groups = "drop")

```
add that average blank absorbance value and the blank corrected absorbance value for each unknown homogenate
```{r}
bca <- bca %>%
  left_join(bca_blank_df, by = "plate") %>%
  mutate(abs562_blankcorr = abs562 - bca_blank_abs)
```

```{r}
# make sure to drop the na for standard D tech rep 3 of plate 1
bca_std_df <- bca %>%
  filter(type == "standard", !is.na(known_mg_ml)) %>%
  filter(!is.na(abs562), !is.na(abs562_blankcorr))


ggplot(bca_std_df, aes(x = known_mg_ml, y = abs562)) +
  geom_point(size = 3) +
  theme_classic(base_size = 14) +
  labs(x = "BSA standard (mg/mL)", y = "Absorbance @562")
```


Create a linear model to fit standard and unknown data
```{r}
# this will drop the 0 for our linear model so that there is no issue in the math
bca_fit0 <- lm(abs562_blankcorr ~ 0 + known_mg_ml, data = bca_std_df)
summary(bca_fit0)


ggplot(bca_std_df, aes(x = known_mg_ml, y = abs562)) +
  geom_point(size=3) +
  stat_smooth(method="lm", se=FALSE, color="red") +
  theme_classic()

```

```{r}
b_slope_bca <- coef(bca_fit0)[1]   # this is 1.28361-ish

bca <- bca %>%
  mutate(
    protein_mg_ml_calc  = abs562_blankcorr / b_slope_bca,
    protein_mg_ml_final = protein_mg_ml_calc * 4
  )


bca %>%
  filter(type=="standard") %>%
  select(homogenate, known_mg_ml, protein_mg_ml_calc) %>%
  arrange(known_mg_ml)
# the protien calc should match that of the known standards

bca %>%
  filter(type=="standard") %>%
  ggplot(aes(x = known_mg_ml, y = protein_mg_ml_calc)) +
  geom_point(size=3) +
  geom_abline(slope=1, intercept=0, linetype="dashed", color="red") +
  theme_classic() +
  labs(x="True mg/mL", y="Calculated mg/mL")
```

```{r}
bca_summary <- bca %>%
  filter(type == "unknown") %>%
  mutate(homogenate = as.numeric(homogenate)) %>%
  group_by(plate, homogenate) %>%
  summarise(
    mean_protein_mg_ml = mean(protein_mg_ml_final, na.rm = TRUE),
    sd_protein_mg_ml   = sd(protein_mg_ml_final, na.rm = TRUE),
    n = sum(!is.na(protein_mg_ml_final)),
    .groups = "drop"
  )


```




#Blastogenic stage & metadata
```{r}
setwd('..')
blast <- read.csv("data/LC50.csv")
```

5 time points * 8 replicates

Should be 40 entries per concentration (over 40 is ok)

```{r}
blast <- blast %>% 
  mutate(hpe = as.factor(hpe)) %>%
  mutate(NiCl2.Nom.Conc. = as.factor(NiCl2.Nom.Conc.))

head(blast)
summary(blast)
```

```{r}
setwd('..')
metadata <- read.csv("data/metadata.csv")
```

In the BCA and SOD data frame, we are missing the hpe associated with the each sample. We can add this on to a new data frame that also combines it with the SOD data after we take the averages and standard errors of the technical replicates of the BCA assay.

::: {.callout-note}
Note that as of July 3, 2024, the data set for the 10 mg/L is incomplete in this data frame and should be taken with a grain of salt or removed from the data frame below. The 0 mg/L treatment is also incomplete with homogenate 37 needing to be re-evaluated.
:::



#Data Munging to combine data frames!

Modify SOD metadata to merge with other data frames more easily
```{r}
metadata <- metadata %>%
  rename(homogenate = hom_num) %>%   # rename column first
  select(homogenate, Tunicate.ID, date, hpe, NiCl2.Nom.Conc., true_rep, rep_exp) %>%
  mutate(NiCl2.Nom.Conc. = as.factor(NiCl2.Nom.Conc.)) %>%
  mutate(hpe = as.factor(hpe)) %>%
  mutate(homogenate = as.factor(homogenate))

summary(metadata)

metadata2 <- metadata %>%
  mutate(homogenate = as.numeric(as.character(homogenate))) # change to numeric for merging data frames

```

::: {.callout-note}
The column sod_avg is in activity units/mL and the column bca_avg is in mg/mL.
:::

```{r}
assay_combo <- bca_summary %>%
  full_join(sod_summary, by = c("homogenate")) %>%
   rename(
    n_bca = n.x,
    n_sod = n.y,
    plate_bca = plate.x,
    plate_sod = plate.y
  )

assay_combo <- assay_combo %>%
  mutate(
    sod_u_mg = mean_sod / mean_protein_mg_ml
  )

```

```{r}
combo_metadata <- assay_combo %>%
  full_join(metadata2, by = "homogenate")
```

ok combine with blastogenic data
```{r}
combo <- combo_metadata %>%
  left_join(
    blast,
    by = c("Tunicate.ID", "NiCl2.Nom.Conc.", "hpe")
  )
```

```{r}
combo <- combo %>%
  filter(!is.na(sod_u_mg)) %>%
  filter(NiCl2.Nom.Conc. != 10) 
summary(combo)
```
```{r}
combo <- combo %>%
  mutate(simple_stage = case_when(
    stage %in% c("A1", "A2") ~ "A",
    stage %in% c("B1", "B2") ~ "B",
    stage %in% c("C1", "C2") ~ "C",
    stage == "D" ~ "D",
    TRUE ~ NA_character_  # This will handle any other cases or return NA if none match
  )) %>%
    mutate(simple_stage = as.factor(simple_stage))

summary(combo)
```

```{r}
combo24 <- combo %>%
  filter(hpe == 24)

combo96 <- combo %>%
  filter(hpe == 96)

summary(combo24)
summary(combo96)
```





# Exploratory Plots
```{r}

ggplot(combo24, aes(x = NiCl2.Nom.Conc., y = sod_u_mg, fill = hpe)) +
  geom_point() +
  geom_violin(trim = FALSE) +
  facet_wrap(~ simple_stage) +
  labs(title = "Violin Plot of SOD Activity (u/mL) at 24 hpe by Treatment and stage",
       fill = "HPE",
       x = "Treatment",
       y = "SOD Activity") 

```

```{r}

ggplot(combo96, aes(x = NiCl2.Nom.Conc., y = sod_u_mg, fill = hpe)) +
  geom_point() +
  geom_violin(trim = FALSE) +
  facet_wrap(~ simple_stage) +
  labs(title = "Violin Plot of SOD Activity (u/mL) by Treatment and stage",
       fill = "HPE",
       x = "Treatment",
       y = "SOD Activity") 
```

```{r}

ggplot(combo, aes(x = NiCl2.Nom.Conc., y = sod_u_mg, fill = hpe)) +
  geom_point() +
  geom_violin(trim = FALSE) +
  facet_wrap(~ simple_stage, ncol=2) +
  labs(title = "Violin Plot of SOD Activity (u/mL) by Treatment and hpe and stage",
       fill = "HPE",
       x = "Treatment",
       y = "SOD Activity") 
```



"Oxidative stress does change with the blastogenic stage of Botryllus schlosseri naturally. Botryllus schlosseri, a colonial ascidian, undergoes a cyclic process called blastogenesis, which includes different stages: bud formation, growth, and take-over (zooid death and replacement by a new generation). During these stages, physiological and biochemical changes occur, including variations in oxidative stress levels."


Note that the plot below is the unormalized data. A BCA was run on the samples as well to quantify total protein content.
```{r, eval=TRUE}
ggplot(combo, aes(x = NiCl2.Nom.Conc., y = mean_sod, fill = NiCl2.Nom.Conc.)) +
  geom_point() +
  geom_violin(trim = FALSE) +
  facet_wrap(~ hpe, scales = "free_y") +
  labs(title = "Violin Plot of SOD Activity (u/mL) by Treatment and HPE",
       fill = "Nickel Concentration",
       x = "Treatment",
       y = "SOD Activity") 
```

## SOD1 activity normalized to the protein content per sample:
```{r, eval=TRUE}

ggplot(combo, aes(x = NiCl2.Nom.Conc., y = sod_u_mg, fill = hpe)) +
  geom_violin(trim = FALSE)  +
  labs(title = "Violin Plot of SOD Activity (u/mg) by Nickel and hpe",
       x = "Nickel Concnetration mg/L",
       y = "SOD Activity") 
```


Fancy kruskil-wallis done in plot, no need to use
```{r}
library(ggstatsplot)
setwd('..')
png(filename = "output/violin_sod_krusk_wilcoxn_hompcorrection.png", width = 1800, height = 1800)
grouped_ggbetweenstats(
  data = combo,
  x = NiCl2.Nom.Conc.,
  y = sod_u_mg,
  grouping.var = hpe,
  type = "all",
  outlier.tagging = TRUE,
  xlab = "Nominal NiCl2 (mg/L)",
  ylab = "SOD1 U/mg",
  pairwise.display = "all",
  results.subtitle = FALSE,
  digits = 2L,
  package = "wesanderson", ## package from which color palette is to be taken
  palette = "Moonrise3",  
   ggsignif.args = list(
    textsize = 10,      # this controls the text size of the pairwise comparisons
    tip_length = 0.1,
    step_increase = 0.2
  ),
  point.args = list(
    alpha = 1,
    size = 10),
  centrality.point.args = list(size = 10, color = "orangered3"),
  centrality.label.args = list(
    alpha = 0,
    size  = 9, 
    nudge_x = 0.5, 
    nudge_y = 9),
  ggplot.component = list (
    ggplot2::scale_y_continuous(
    breaks = seq(0, 6, by = 0.5),
    limits = (c(0, 6))),
    theme(
    axis.ticks = element_blank(),
    axis.line = element_line(colour = "grey50"),
    panel.grid = element_line(color = "#b4aea9"),
    panel.grid.minor = element_blank(),
    panel.grid.major.x = element_blank(),
    panel.grid.major.y = element_line(linetype = "dashed"),
    panel.background = element_rect(fill = "white", color = "white"),
    plot.background = element_rect(fill = "white", color = "white"),
    axis.text = element_text(size = 30),   # Adjust the size of the axis labels
    axis.title = element_text(size = 40),
    axis.text.y = element_text(size = 30, hjust = 1.5, margin = margin(r = 20)),
    axis.text.x = element_text(size = 30, vjust = 3, hjust = 0.5, margin = margin(t = 20))
  )
 ) 
) 
dev.off()

```




```{r}

# Ensure concentrations plot in numeric order (but treated as discrete groups)
combo_plot <- combo %>%
  mutate(
    NiCl2.Nom.Conc. = factor(NiCl2.Nom.Conc.,
                             levels = sort(unique(as.numeric(as.character(NiCl2.Nom.Conc.))))),
    hpe = factor(hpe)
  )

n_counts <- combo_plot %>%
  group_by(hpe, NiCl2.Nom.Conc.) %>%
  summarise(n = n(), .groups = "drop")

```

just violin
```{r}

ggplot(combo_plot, aes(x = NiCl2.Nom.Conc., y = sod_u_mg)) +
  geom_violin(trim = FALSE, width = 0.9, alpha = 0.6) +
  geom_jitter(width = 0.12, height = 0, size = 3, alpha = 0.9) +
  # Median dot per group
  stat_summary(fun = median, geom = "point", size = 4, color="blue") +
  # Optional: median line inside each violin
  stat_summary(fun = median, geom = "crossbar", width = 0.6, fatten = 0) +
  facet_wrap(~ hpe, nrow = 1) +
  scale_y_continuous(breaks = seq(0, 5, by = 1), limits = c(0, 5), expand = c(0.2, 0)) +
  labs(x = "Nickel (II) Chloride Concentration (mg/L)", y = "SOD1 (U/mg)") +
  geom_text(
  data = n_counts,
  aes(x = NiCl2.Nom.Conc., y = 0, label = paste0("n=", n)),
  vjust = 1.5,
  size = 6,
  inherit.aes = FALSE
)+
  theme_minimal(base_size = 18) +
  theme(
    axis.ticks = element_blank(),
    axis.line = element_line(colour = "grey50"),
    panel.grid.minor.x = element_blank(),
    panel.grid.minor.y = element_blank(),
    panel.grid.major.x = element_blank(),
    panel.grid.major.y = element_line(linetype = "dashed"),
    panel.background = element_rect(fill = "white", color = "white"),
    plot.background  = element_rect(fill = "white", color = "white"),
    axis.text = element_text(size = 18),
    axis.title = element_text(size = 20),
    axis.text.y = element_text(hjust = 1.2, margin = margin(r = 10)),
    axis.text.x = element_text(vjust = 2, margin = margin(t = 10))
  )

#ggsave("output/violin_sod_median_facets.png", p_violin, width = 12, height = 5, dpi = 300)


```
# Just boxplot, Final Figure 

```{r}
png(filename = "../output/boxplot_sod_RnormalizedBCA.png", width = 1300, height = 850)
ggplot(combo_plot, aes(x = NiCl2.Nom.Conc., y = sod_u_mg)) +
  geom_boxplot(width = 0.7, outlier.shape = NA, alpha = 0.6) +
  geom_jitter(width = 0.01, height = 0, size = 4, alpha = 0.9,
              aes(color = simple_stage)) +
  stat_summary(fun = median, geom = "point", size = 4, color="blue") +
  facet_wrap(~ hpe, nrow = 1,
             labeller = labeller(
    hpe = function(x) paste0(x, " hpe"))) +
  scale_y_continuous(breaks = seq(0, 5, by = 0.5), limits = c(0, 5), expand = c(0.05, 0.1)) +
  labs(x = "Nickel (II) Chloride Concentration (mg/L)", 
       y = "SOD1 Activity (U/mg protein)",
       color = "Stage") +
  geom_text(
  data = n_counts,
  aes(x = NiCl2.Nom.Conc., y = 0, label = paste0("n=", n)),
  vjust = 1.5,
  size = 8,
  inherit.aes = FALSE
)+
  theme_minimal(base_size = 18) +
  theme(
    axis.ticks = element_blank(),
    axis.line = element_line(colour = "grey50"),
    panel.grid.minor = element_blank(),
    panel.grid.major.x = element_blank(),
    panel.grid.major.y = element_line(linetype = "dashed"),
    panel.background = element_rect(fill = "white", color = "grey"),
    plot.background  = element_rect(fill = "white", color = "white"),
    strip.background = element_rect(fill = "grey"),
    strip.text = element_text(size = 28, face = "bold"),
    axis.text = element_text(size = 18),
    axis.title = element_text(size = 30),
    axis.text.y = element_text(hjust = 1.2, margin = margin(r = 10), size = 25),
    axis.text.x = element_text(vjust = 2, margin = margin(t = 10), size =25)
  )
dev.off()
```
combine them (boxplot + violin)
```{r}
ggplot(combo_plot, aes(x = NiCl2.Nom.Conc., y = sod_u_mg)) +
    geom_violin(trim = FALSE, width = 0.9, alpha = 0.6) +
  geom_boxplot(width = 0.7, outlier.shape = NA, alpha = 0.6) +
  geom_jitter(width = 0.12, height = 0, size = 3, alpha = 0.9) +
  stat_summary(fun = median, geom = "point", size = 4, color="blue") +
  facet_wrap(~ hpe, nrow = 1) +
  scale_y_continuous(breaks = seq(0, 40, by = 10), limits = c(0, 40)) +
  labs(x = "Nickel (II) Chloride Concentration (mg/L)", y = "SOD1 (U/mg)") +
  theme_minimal(base_size = 18) +
  theme(
    axis.ticks = element_blank(),
    axis.line = element_line(colour = "grey"),
    panel.grid.minor = element_blank(),
    panel.grid.major.x = element_blank(),
    panel.grid.major.y = element_line(linetype = "dashed"),
    strip.background = element_rect(fill = "grey", color = "grey"),
    panel.background = element_rect(fill = "white", color = "black"),
    plot.background  = element_rect(fill = "white", color = "grey"),
    axis.text = element_text(size = 18),
    axis.title = element_text(size = 20),
    axis.text.y = element_text(hjust = 1.2, margin = margin(r = 10)),
    axis.text.x = element_text(vjust = 2, margin = margin(t = 10))
  )
```





```{r}
ggplot(combo, aes(x = NiCl2.Nom.Conc., y = sod_u_mg, fill = NiCl2.Nom.Conc.)) +
  geom_violin(trim = FALSE) +
  facet_wrap(~ hpe) +
  labs(title = "Violin Plot of SOD Activity (u/mg) by Treatment and HPE",
       fill = "Nickel Concentration",
       x = "Treatment",
       y = "SOD Activity") 
```

# Statistical Analysis

We will run a two-way ANOVA on the data exploring sod1 activity units/mg of protein by hours post exposure and nickel concentration.

```{r}
# Perform ANOVA
anova_result <- aov(sod_u_mg ~ hpe * NiCl2.Nom.Conc., data = combo)

# Summarize ANOVA results
summary(anova_result)
```

## ANOVA assumptions

```{r}
# Check histogram of transformed data
hist(combo$sod_u_mg, main = "Distribution", xlab = "SOD U/mg")

# Check normality of data (optional)
shapiro.test(combo$sod_u_mg)

# Perform Levene's test on data
leveneTest(sod_u_mg ~ NiCl2.Nom.Conc., data = combo)
```

## ANOVA Conclusions

SOD1 activity does not differ across nickel concentration treatment groups or even the control at either the 24 or 96 hours post exposure mark.

# Next Steps?

There could be various reasons why we did not observe the expected effect of increased SOD activity with increasing concentrations of nickel.

## Power Analysis
Currently this will only work below if the groups are of equal sample size. Because I have yet to re-process the homogenate 37 (the final replicate for the control) this analysis cannot work.

```{r}
library(pwr)
anova_result <- aov(sod_u_mg ~ hpe * NiCl2.Nom.Conc., data = combo)
summary_result <- summary(anova_result)

# Extract the sum of squares
ss_total <- sum(summary_result[[1]][, "Sum Sq"])
ss_residual <- summary_result[[1]]["Residuals", "Sum Sq"]

# Calculate eta squared
eta_squared <- 1 - (ss_residual / ss_total)

# Calculate effect size f
effect_size_f <- sqrt(eta_squared / (1 - eta_squared))
```

```{r}
# Number of groups in your ANOVA (e.g., hpe * treatment)
num_groups <- length(unique(combo$hpe)) * length(unique(combo$NiCl2.Nom.Conc.))

# Significance level (commonly set to 0.05)
alpha <- 0.05

# Sample size (total number of observations)
sample_size <- nrow(combo)

# Conduct power analysis
power_analysis <- pwr.anova.test(k = num_groups, f = effect_size_f, sig.level = alpha, n = sample_size / num_groups)

# Print the result
print(power_analysis)

```
Note that n = 7.5 is in relation to the unequal sample sizes per group which is in relation to the missing control sample, homogenate 37.

Power (0.1781299): The power of 0.1238 indicates that this study has a low probability (approximately 17.8%) of detecting the true effect (f = 0.2437383) under the current conditions (sample sizes, effect size, and significance level).

Considerations: To increase power, we may need to consider increasing the sample size per group, using more sensitive measures, or adjusting your study design to reduce variability.

